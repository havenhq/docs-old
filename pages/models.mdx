# Supported Models

Haven implements model classes that are defined by a model's architecture (e.g. `MPTForCausalLM`) and its number of weights. 
This does however not mean that a single model class corresponds to a single model as it can be found on Huggingface - a single model class can support various models with different weights (e.g. `mpt_7b` supports `mosaicml/mpt-7b-instruct` and `mosaicml/mpt-7b-chat`).
A model class can be mapped to multiple configurations, which are defined by the GPU types, the number of GPUs as well as the quantization format different models can be deployed with.
Below, you can find all of our supported models. We're constantly adding new models and deployment configs, so keep tabs on this page!

**You can use Haven with any model from Huggingface as long as its architecture is supported**. To see how to do so, refer to the guide about [custom models]().

### List of Supported Models

#### `gpt_neox_3b`:

**Preconfigured Models:**

No preconfigured models. To quickly add models, refer to our [guide](https://docs.haven.run/guides/add_models)

**Deployment Configurations:**


| quantization | gpu_type    | gpu_count    |
| ------------ | ----------- | ----------- |
| `float16`       | `A100`      | `1` |
| `float16`       | `T4`      | `1` |



#### `gpt_neox_7b`:

**Preconfigured Models:**

No preconfigured models. To quickly add models, refer to our [guide](https://docs.haven.run/guides/add_models)

**Deployment Configurations:**


| quantization | gpu_type    | gpu_count    |
| ------------ | ----------- | ----------- |
| `float16`       | `A100`      | `1` |
| `float16`       | `T4`      | `2` |



#### `gpt_neox_12b`:

**Preconfigured Models:**

- `@huggingface/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5`


**Deployment Configurations:**


| quantization | gpu_type    | gpu_count    |
| ------------ | ----------- | ----------- |
| `float16`       | `A100`      | `1` |




#### `llama_7b`:

**Preconfigured Models:**

- `@huggingface/h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b`


**Deployment Configurations:**


| quantization | gpu_type    | gpu_count    |
| ------------ | ----------- | ----------- |
| `float16`       | `A100`      | `1` |
| `float16`       | `T4`      | `2` |




#### `llama_13b`:

**Preconfigured Models:**

- `@huggingface/h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-13b`


**Deployment Configurations:**


| quantization | gpu_type    | gpu_count    |
| ------------ | ----------- | ----------- |
| `float16`       | `A100`      | `1` |




#### `mpt_7b`:

**Preconfigured Models:**

- `@huggingface/mosaicml/mpt-7b-instruct`
- `@huggingface/mosaicml/mpt-7b-chat`


**Preconfigured Configurations:**


| quantization | gpu_type    | gpu_count    |
| ------------ | ----------- | ----------- |
| `float16`       | `A100`      | `1` |
| `float16`       | `T4`      | `2` |



#### `mpt_30b`:

**Preconfigured Models:**

- `@huggingface/mosaicml/mpt-30b-instruct`
- `@huggingface/mosaicml/mpt-30b-chat`


**Deployment Configurations:**


| quantization | gpu_type    | gpu_count    |
| ------------ | ----------- | ----------- |
| `float16`       | `A100`      | `2` |

