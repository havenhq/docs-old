# Getting started with Haven

Haven helps you deploy open-source LLMs in your own cloud.

## Installation

Haven comes as a docker image. It can be deployed anywhere you like and will be responsible for spinning up and managing all additional resources you want to run your LLMs on.

**The fastest and easiest way to get Haven running is using the GCloud CLI.**

### 1. Create a Service Account

**Prerequisites**:\
You have a Google Cloud account and have the gcloud CLI installed.

1. Haven uses [Service Accounts](https://cloud.google.com/iam/docs/service-account-overview) to create resources on GCP. Create one running this command:

```bash copy
gcloud iam service-accounts create haven-service-account --project=<your-project-id>
```

Your project ID is the ID of the project you want to deploy Haven in. You can find it in the [GCP console](https://console.cloud.google.com/). The dropdown in the top left corner shows you the project IDs of all of your projects.

2. Assign the service account the role of an editor

```bash copy
gcloud projects add-iam-policy-binding <your-project-id> --member="serviceAccount:haven-service-account@<your-project-id>.iam.gserviceaccount.com" --role="roles/editor"
```

3. Download the service account file

```bash copy
gcloud iam service-accounts keys create ./key.json --iam-account=haven-service-account@<your-project-id>.iam.gserviceaccount.com
```

### 2. Deploy Haven

We recommend to run Haven inside GCP, since that is where resources will be created. That way, the resources Haven creates for you are **as close to the deployment as possible**. Haven's components use GRPC and communicate over ports 50051 and 50052. Depending on your existing settings, you might have to configure your firewall settings to enable communication:

```bash copy
gcloud compute firewall-rules create allow-50051 --allow tcp:50051 --target-tags http-server
gcloud compute firewall-rules create allow-50052 --allow tcp:50052 --target-tags http-server
```

Afterwards, the command below lets you set up a Haven manager instance with one `gcloud` command. A bearer token can be passed that will be used to authenticate a client (likely you using the SDK) trying to make requests to the Haven manager.

```bash copy
gcloud compute instances create-with-container haven-manager --container-image havenhq/haven --machine-type e2-micro --container-env BEARER_TOKEN=<some-bearer-token> --tags=http-server,https-server
```

You might get asked to select a project. In that case, you can add the `--project <project-id>` flag to the command above.

### 3. Add your Service Account

Almost done! The last step now is to start calling your Haven deployment with one of our SDKs.

```bash copy
pip install havenpy
```

```python copy
from havenpy import Haven
client = Haven("<ip-adress-of-your-vm>:50051", "<your-bearer-token>")

# Now you can add your google cloud service account file to the deployment
with open("key.json", "r") as f:
	client.setup(key_file=f.read())
```

### 4. Enjoy

You're done! Here are some things you can do with Haven:

```python filename="python" copy
# Create a worker running the mpt-7b-chat model from Huggingface
worker_id = client.create_inference_worker(
	model_name="@huggingface/mosaicml/mpt-7b-chat",
	quantization="float16", gpu_type="A100", gpu_count=1)

print(worker_id)
```

Now we wait until the worker is running. This takes around 10 min depending on the model size. After it started up, you can integrate it into your product like this:

```python filename="python" copy
res = client.chat_completion(worker_id, messages=[{
	"content": "Write a newspaper article about Marc Zuckerberg.",
	"role": "USER"
}], stream=True)

for r in res:
	print(r.text)
```

Congrats! You are now using open-source LLMs in your own cloud.
